import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import tensorflow as tf
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import logging
import json
from datetime import datetime

from config.config import MODEL_CONFIG, TRAINED_MODEL_PATH, LOGS_DIR, MODEL_DIR
from scripts.data_preparation import PestDataPreprocessor
from scripts.model_architecture import PestDetectionModel, FocalLoss, F1Score

# Set up logging
LOGS_DIR.mkdir(exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOGS_DIR / 'training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class PestModelTrainer:
    def __init__(self, model_type='transfer_learning'):
        self.model_type = model_type
        self.model = None
        self.history = None
        self.data_preprocessor = PestDataPreprocessor()
        self.model_builder = PestDetectionModel()
        
        # Ensure model directory exists
        MODEL_DIR.mkdir(exist_ok=True)
        
    def prepare_data(self, data_dir=None):
        """Prepare training, validation, and test data"""
        logger.info("Preparing dataset...")
        
        # Prepare dataset
        data_package = self.data_preprocessor.prepare_dataset(data_dir)
        
        self.train_generator = data_package['train_generator']
        self.val_generator = data_package['val_generator']
        self.test_data = data_package['test_data']
        self.class_names = data_package['class_names']
        
        logger.info(f"Data preparation completed. Classes: {len(self.class_names)}\")\n        logger.info(f"Train samples: {self.train_generator.samples}\")\n        logger.info(f"Val samples: {self.val_generator.samples}\")\n        logger.info(f"Test samples: {len(self.test_data[0])}\")\n        \n        return data_package\n    \n    def build_model(self):\n        \"\"\"Build the model based on specified type\"\"\"\n        logger.info(f\"Building {self.model_type} model...\")\n        \n        self.model = self.model_builder.build_model(self.model_type)\n        \n        # Print model summary\n        logger.info(\"Model architecture:\")\n        self.model.summary()\n        \n        return self.model\n    \n    def train_model(self, epochs=None, use_focal_loss=False):\n        \"\"\"Train the model with advanced techniques\"\"\"\n        if self.model is None:\n            raise ValueError(\"Model not built. Call build_model() first.\")\n        \n        epochs = epochs or MODEL_CONFIG['epochs']\n        \n        logger.info(f\"Starting training for {epochs} epochs...\")\n        \n        # Setup callbacks\n        model_path = MODEL_DIR / f\"best_model_{self.model_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\"\n        callbacks = self.model_builder.get_callbacks(str(model_path))\n        \n        # Add custom callbacks\n        callbacks.extend([\n            tf.keras.callbacks.CSVLogger(\n                LOGS_DIR / f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n            ),\n            tf.keras.callbacks.TensorBoard(\n                log_dir=LOGS_DIR / \"tensorboard\" / datetime.now().strftime('%Y%m%d_%H%M%S'),\n                histogram_freq=1,\n                write_graph=True,\n                write_images=True\n            )\n        ])\n        \n        # Recompile with focal loss if requested\n        if use_focal_loss:\n            logger.info(\"Using Focal Loss for training...\")\n            self.model.compile(\n                optimizer=tf.keras.optimizers.Adam(learning_rate=MODEL_CONFIG['learning_rate']),\n                loss=FocalLoss(),\n                metrics=['accuracy', F1Score(), 'precision', 'recall']\n            )\n        \n        # Calculate steps per epoch\n        steps_per_epoch = self.train_generator.samples // MODEL_CONFIG['batch_size']\n        validation_steps = self.val_generator.samples // MODEL_CONFIG['batch_size']\n        \n        # Train model\n        try:\n            self.history = self.model.fit(\n                self.train_generator,\n                epochs=epochs,\n                steps_per_epoch=steps_per_epoch,\n                validation_data=self.val_generator,\n                validation_steps=validation_steps,\n                callbacks=callbacks,\n                verbose=1\n            )\n            \n            logger.info(\"Training completed successfully!\")\n            \n            # Save final model\n            final_model_path = MODEL_DIR / f\"final_model_{self.model_type}.h5\"\n            self.model.save(str(final_model_path))\n            logger.info(f\"Final model saved to {final_model_path}\")\n            \n        except Exception as e:\n            logger.error(f\"Training failed: {str(e)}\")\n            raise\n        \n        return self.history\n    \n    def fine_tune_model(self, base_model, fine_tune_epochs=20):\n        \"\"\"Fine-tune the model for better accuracy\"\"\"\n        if self.model_type != 'transfer_learning':\n            logger.warning(\"Fine-tuning is only applicable to transfer learning models\")\n            return\n        \n        logger.info(\"Starting fine-tuning...\")\n        \n        # Unfreeze base model\n        base_model.trainable = True\n        \n        # Fine-tune from this layer onwards\n        fine_tune_at = len(base_model.layers) // 2\n        \n        # Freeze all layers before fine_tune_at\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable = False\n        \n        # Use lower learning rate for fine-tuning\n        self.model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),\n            loss='categorical_crossentropy',\n            metrics=['accuracy', 'precision', 'recall']\n        )\n        \n        # Setup callbacks for fine-tuning\n        ft_model_path = MODEL_DIR / f\"fine_tuned_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.h5\"\n        ft_callbacks = [\n            tf.keras.callbacks.EarlyStopping(\n                monitor='val_accuracy',\n                patience=5,\n                restore_best_weights=True\n            ),\n            tf.keras.callbacks.ModelCheckpoint(\n                filepath=str(ft_model_path),\n                monitor='val_accuracy',\n                save_best_only=True,\n                verbose=1\n            )\n        ]\n        \n        # Calculate steps\n        steps_per_epoch = self.train_generator.samples // MODEL_CONFIG['batch_size']\n        validation_steps = self.val_generator.samples // MODEL_CONFIG['batch_size']\n        \n        # Fine-tune\n        fine_tune_history = self.model.fit(\n            self.train_generator,\n            epochs=fine_tune_epochs,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=self.val_generator,\n            validation_steps=validation_steps,\n            callbacks=ft_callbacks,\n            verbose=1\n        )\n        \n        logger.info(\"Fine-tuning completed!\")\n        return fine_tune_history\n    \n    def evaluate_model(self):\n        \"\"\"Evaluate model performance on test data\"\"\"\n        if self.model is None or self.test_data is None:\n            raise ValueError(\"Model and test data must be available\")\n        \n        logger.info(\"Evaluating model performance...\")\n        \n        X_test, y_test = self.test_data\n        \n        # Evaluate on test data\n        test_loss, test_accuracy, test_precision, test_recall = self.model.evaluate(\n            X_test, y_test, verbose=0\n        )[:4]\n        \n        # Get predictions\n        y_pred = self.model.predict(X_test)\n        y_pred_classes = np.argmax(y_pred, axis=1)\n        y_true_classes = np.argmax(y_test, axis=1)\n        \n        # Calculate additional metrics\n        from sklearn.metrics import f1_score, accuracy_score\n        f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n        accuracy = accuracy_score(y_true_classes, y_pred_classes)\n        \n        # Create evaluation report\n        evaluation_results = {\n            'test_accuracy': float(accuracy),\n            'test_precision': float(test_precision),\n            'test_recall': float(test_recall),\n            'test_f1_score': float(f1),\n            'test_loss': float(test_loss),\n            'model_type': self.model_type,\n            'num_classes': len(self.class_names),\n            'test_samples': len(X_test)\n        }\n        \n        logger.info(f\"Evaluation Results:\")\n        logger.info(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n        logger.info(f\"Test Precision: {test_precision:.4f}\")\n        logger.info(f\"Test Recall: {test_recall:.4f}\")\n        logger.info(f\"Test F1-Score: {f1:.4f}\")\n        \n        # Save evaluation results\n        eval_path = LOGS_DIR / f\"evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n        with open(eval_path, 'w') as f:\n            json.dump(evaluation_results, f, indent=2)\n        \n        # Generate classification report\n        report = classification_report(\n            y_true_classes, y_pred_classes,\n            target_names=self.class_names,\n            output_dict=True\n        )\n        \n        # Save classification report\n        report_path = LOGS_DIR / f\"classification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n        with open(report_path, 'w') as f:\n            json.dump(report, f, indent=2)\n        \n        # Create and save confusion matrix\n        self.plot_confusion_matrix(y_true_classes, y_pred_classes)\n        \n        return evaluation_results\n    \n    def plot_confusion_matrix(self, y_true, y_pred):\n        \"\"\"Plot and save confusion matrix\"\"\"\n        cm = confusion_matrix(y_true, y_pred)\n        \n        plt.figure(figsize=(15, 12))\n        sns.heatmap(\n            cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=self.class_names,\n            yticklabels=self.class_names\n        )\n        plt.title('Confusion Matrix')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.xticks(rotation=45, ha='right')\n        plt.yticks(rotation=0)\n        plt.tight_layout()\n        \n        # Save plot\n        cm_path = LOGS_DIR / f\"confusion_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n        plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n        plt.close()\n        \n        logger.info(f\"Confusion matrix saved to {cm_path}\")\n    \n    def plot_training_history(self):\n        \"\"\"Plot and save training history\"\"\"\n        if self.history is None:\n            logger.warning(\"No training history available\")\n            return\n        \n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n        \n        # Accuracy\n        axes[0, 0].plot(self.history.history['accuracy'], label='Train Accuracy')\n        axes[0, 0].plot(self.history.history['val_accuracy'], label='Val Accuracy')\n        axes[0, 0].set_title('Model Accuracy')\n        axes[0, 0].set_xlabel('Epoch')\n        axes[0, 0].set_ylabel('Accuracy')\n        axes[0, 0].legend()\n        axes[0, 0].grid(True)\n        \n        # Loss\n        axes[0, 1].plot(self.history.history['loss'], label='Train Loss')\n        axes[0, 1].plot(self.history.history['val_loss'], label='Val Loss')\n        axes[0, 1].set_title('Model Loss')\n        axes[0, 1].set_xlabel('Epoch')\n        axes[0, 1].set_ylabel('Loss')\n        axes[0, 1].legend()\n        axes[0, 1].grid(True)\n        \n        # Precision\n        if 'precision' in self.history.history:\n            axes[1, 0].plot(self.history.history['precision'], label='Train Precision')\n            axes[1, 0].plot(self.history.history['val_precision'], label='Val Precision')\n            axes[1, 0].set_title('Model Precision')\n            axes[1, 0].set_xlabel('Epoch')\n            axes[1, 0].set_ylabel('Precision')\n            axes[1, 0].legend()\n            axes[1, 0].grid(True)\n        \n        # Recall\n        if 'recall' in self.history.history:\n            axes[1, 1].plot(self.history.history['recall'], label='Train Recall')\n            axes[1, 1].plot(self.history.history['val_recall'], label='Val Recall')\n            axes[1, 1].set_title('Model Recall')\n            axes[1, 1].set_xlabel('Epoch')\n            axes[1, 1].set_ylabel('Recall')\n            axes[1, 1].legend()\n            axes[1, 1].grid(True)\n        \n        plt.tight_layout()\n        \n        # Save plot\n        history_path = LOGS_DIR / f\"training_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n        plt.savefig(history_path, dpi=300, bbox_inches='tight')\n        plt.close()\n        \n        logger.info(f\"Training history plot saved to {history_path}\")\n    \n    def save_model_for_production(self, model_name=\"pest_detection_model\"):\n        \"\"\"Save model in production-ready format\"\"\"\n        if self.model is None:\n            raise ValueError(\"No model to save\")\n        \n        # Save in multiple formats for flexibility\n        \n        # 1. Save as H5 format\n        h5_path = MODEL_DIR / f\"{model_name}.h5\"\n        self.model.save(str(h5_path))\n        \n        # 2. Save as TensorFlow SavedModel format\n        savedmodel_path = MODEL_DIR / f\"{model_name}_savedmodel\"\n        tf.saved_model.save(self.model, str(savedmodel_path))\n        \n        # 3. Save model configuration\n        config = {\n            'model_type': self.model_type,\n            'input_shape': self.model_builder.input_shape,\n            'num_classes': self.model_builder.num_classes,\n            'class_names': self.class_names,\n            'model_config': self.model.get_config(),\n            'training_params': MODEL_CONFIG\n        }\n        \n        config_path = MODEL_DIR / f\"{model_name}_config.json\"\n        with open(config_path, 'w') as f:\n            json.dump(config, f, indent=2, default=str)\n        \n        logger.info(f\"Production model saved:\")\n        logger.info(f\"  H5 format: {h5_path}\")\n        logger.info(f\"  SavedModel: {savedmodel_path}\")\n        logger.info(f\"  Config: {config_path}\")\n        \n        return {\n            'h5_path': str(h5_path),\n            'savedmodel_path': str(savedmodel_path),\n            'config_path': str(config_path)\n        }\n    \n    def full_training_pipeline(self, data_dir=None, epochs=None, use_fine_tuning=True):\n        \"\"\"Complete training pipeline\"\"\"\n        logger.info(\"Starting full training pipeline...\")\n        \n        try:\n            # 1. Prepare data\n            self.prepare_data(data_dir)\n            \n            # 2. Build model\n            self.build_model()\n            \n            # 3. Train model\n            self.train_model(epochs)\n            \n            # 4. Fine-tune if transfer learning\n            if use_fine_tuning and self.model_type == 'transfer_learning':\n                base_model = None  # Would need to be passed from build_model\n                # self.fine_tune_model(base_model)\n            \n            # 5. Evaluate model\n            results = self.evaluate_model()\n            \n            # 6. Plot training history\n            self.plot_training_history()\n            \n            # 7. Save production model\n            model_paths = self.save_model_for_production()\n            \n            # Check if we achieved target accuracy\n            target_accuracy = 0.97\n            achieved_accuracy = results['test_accuracy']\n            \n            logger.info(f\"\\n{'='*50}\")\n            logger.info(f\"TRAINING PIPELINE COMPLETED\")\n            logger.info(f\"Target Accuracy: {target_accuracy*100:.1f}%\")\n            logger.info(f\"Achieved Accuracy: {achieved_accuracy*100:.2f}%\")\n            \n            if achieved_accuracy >= target_accuracy:\n                logger.info(f\"🎉 SUCCESS: Target accuracy achieved!\")\n            else:\n                logger.info(f\"⚠️  Target accuracy not reached. Consider:\")\n                logger.info(f\"   - More training data\")\n                logger.info(f\"   - Longer training\")\n                logger.info(f\"   - Different model architecture\")\n                logger.info(f\"   - Hyperparameter tuning\")\n            \n            logger.info(f\"{'='*50}\\n\")\n            \n            return {\n                'evaluation_results': results,\n                'model_paths': model_paths,\n                'target_achieved': achieved_accuracy >= target_accuracy\n            }\n            \n        except Exception as e:\n            logger.error(f\"Training pipeline failed: {str(e)}\")\n            raise\n\ndef main():\n    \"\"\"Main training function\"\"\"\n    import argparse\n    \n    parser = argparse.ArgumentParser(description='Train pest detection model')\n    parser.add_argument('--model-type', choices=['advanced_cnn', 'transfer_learning', 'ensemble'],\n                       default='transfer_learning', help='Type of model to train')\n    parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train')\n    parser.add_argument('--data-dir', type=str, help='Path to training data directory')\n    parser.add_argument('--use-fine-tuning', action='store_true', default=True,\n                       help='Use fine-tuning for transfer learning')\n    \n    args = parser.parse_args()\n    \n    # Create trainer\n    trainer = PestModelTrainer(model_type=args.model_type)\n    \n    # Run training pipeline\n    results = trainer.full_training_pipeline(\n        data_dir=args.data_dir,\n        epochs=args.epochs,\n        use_fine_tuning=args.use_fine_tuning\n    )\n    \n    return results\n\nif __name__ == \"__main__\":\n    results = main()"